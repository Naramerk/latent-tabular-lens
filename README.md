# Shifter

Задача: научить нейросеть‑**Shifter** модифицировать стандартный шум Z ~ N(0, I) в латентном пространстве предобученного CTGAN так, чтобы сгенерированные данные имели заданные мета‑характеристики m*.   

---

## Пайплайн состоит из двух этапов. 

### 1) Обучение CTGAN

Обучаем CTGAN на исходных данных. После обучения веса CTGAN **замораживаются** и больше не меняются. 

### 2) Обучение Shifter 

Shifter - это "контролируемая правка" шума перед генератором: мы подаём нормальный шум и m*, а сеть предсказывает небольшой сдвиг, который меняет свойства синтетики на выходе CTGAN.   
У нас это residual‑модель:
z̃_i = z_i + delta_scale · Δ_θ([z_i, c, μ_Z]),
где c = MetaEncoder(m*), μ_Z = mean(Z).
Глобальный вектор c одинаков для всех сэмплов батча, а μ_Z - permutation‑invariant summary батча (mean‑pooling в стиле DeepSets), чтобы сдвиг мог зависеть от "контекста набора" латентов. 

### Что такое “шум” в этой постановке

На каждом шаге обучения Shifter мы заново семплируем базовый шум:
`Z_base = torch.randn(TRAIN_N_SAMPLES, z_dim)`.   
То есть мы не "шумим данные", а каждый раз стартуем от нового Z и учим θ работать устойчиво по разным сэмплам шума. 

Дополнительно CTGAN может использовать условный вектор `cond_vec`, который семплируется как `adapter.sample_cond_vec(TRAIN_N_SAMPLES)` и подаётся в генератор.   
В дифференцируемой генерации `cond_vec` конвертируется в тензор с `requires_grad=False`, поэтому условия не оптимизируются градиентом. 

### Функция потерь

После генерации `X̃` берём числовые колонки и вычисляем значения мета‑фичей `m̂ = M(X̃)`, L_meta = MSE(m̂, m*).   

Итог:
`L_total = L_meta + λ_Z * L_z + λ_X * L_x`, где `L_z` - `latent_reg`, `L_x` - `feature_space_reg`. 

### Backprop

Один шаг обучения соответствует цепочке:  
θ → Z̃ = s_θ(Z, m*) → X̃ = G(Z̃) → m̂ = M(X̃) → L(m̂, m*), затем `loss.backward()` и `opt.step()` обновляют только параметры Shifter. 

### После обучения Shifter:  

1) семплируем `Z = torch.randn(1, N_INFER, z_dim)` и считаем `Z̃ = shifter(Z, target_meta)`,   
2) генерируем shifted‑датасет через `adapter.generate_from_noise(...)`. 
---

### `src/` 

- `src/shifter.py`: `MetaEncoder` (кодирует `m*` → `c`) и `Shifter` (сдвиг `Z → Z̃` через mean‑pooling `μ_Z` + MLP), плюс `latent_reg` и `feature_space_reg`.   
- `src/diff_mfs.py`: `compute_diff_mfs` - дифференцируемые мета‑фичи (mean/median/iq_range и `mut_inf` как Gaussian‑аппроксимация попарной взаимной информации на основе корреляции, то есть не MI(x,y), а MI(Xi,Xj), так как категориальный таргет исключается при вычислении мета-фич и градиенты через него не идут).   
- `src/ctgan_adapter.py`: `CTGANRepoAdapter` - генерация из CTGAN по заданным латентам, включая `generate_from_noise_differentiable` для обучения (строит граф) и `generate_from_noise` для обычного инференса (под `no_grad`). 
